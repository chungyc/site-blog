---
title: Large language models
description: Large language models such as ChatGPT and Bard are impressive, but I think they are overrated a bit too much.
published: 2024-01-10
categories: Computer Science
---

Large language models such as [ChatGPT] and [Bard] have been all the rage lately.
After trying them out for a while, however,
I think the general hype around them may be a tad bit overdone.
The feeling I get is that they are _very_ good at stitching text seamlessly together,
but they do not actually _know_ anything.

<!--more-->

<!-- Describe specifics on how it appears not to know things. -->

There seems to a general feeling that the [Turing Test] is obsolete these days,
but as far as I am concerned, current levels of artificial intelligence
are not quite able to pass it yet.
Yes, there are humans who occasionally display similar levels of mechanical responses
through rote recitation of talking points, but I don't consider these
great displays of intelligence, so they would be the wrong target to compare against.

I am not too worried about machines taking over everything any time soon,
but the sophistication of large language models does make me wonder about our own intelligence.
A large part of machine learning is basically curve fitting,
albeit very sophisticated curve fitting.
Does this have implications for what many things we consider intelligence in ourselves are?
Are they mostly a similar sort of highly sophisticated curve fitting
instead of any sort of conscious thinking?
Or is even conscious thinking ultimately a highly advanced form of curve fitting?

[Bard]: https://bard.google.com/
[ChatGPT]: https://chat.openai.com/
[Turing Test]: https://plato.stanford.edu/entries/turing-test/
